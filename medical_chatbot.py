from flask import Flask, request, jsonify, session, json
import os
from dotenv import load_dotenv
from flask_cors import CORS
import os
import tempfile
from ocr import extract_information_from_image, generate_doctor_advice
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from whatsapp_alerts import send_whatsapp_alert
from datetime import datetime
import textwrap
import math
import gdown
import zipfile

def download_faiss_index():
    faiss_folder = "faiss_index"
    faiss_zip = "faiss_index.zip"
    drive_file_id = "1sjZ-3OftY7nYZ53Z0mzzcx5bkU20cIDY"

    if not os.path.exists(faiss_folder):
        print("FAISS index not found. Downloading...")
        url = f"https://drive.google.com/uc?id={drive_file_id}"
        gdown.download(url, faiss_zip, quiet=False)
        with zipfile.ZipFile(faiss_zip, 'r') as zip_ref:
            zip_ref.extractall(faiss_folder)
        print("Download complete.")

download_faiss_index()

load_dotenv()
os.environ["GOOGLE_API_KEY"] = os.getenv("GEMINI_API_KEY")

app = Flask(__name__)
CORS(app)
app.secret_key = os.getenv("SECRET_KEY", "dev_secret")

# Gemini model setup
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.2)

# Embeddings + FAISS
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

# Memory init
def init_memory():
    if "history" not in session:
        session["history"] = []


@app.route("/sos", methods=["POST"])
def send_sos_alert():
    try:
        sos_message = """
    üö® *Emergency Alert Triggered!*

    An SOS button was clicked by the user. Immediate attention is required. 
    Please reach out to them and verify their condition.

    üïí Time: {}
    üìç Status: User marked as needing help.

    _This message was auto-generated by the Health Assistant Platform._
    """.format(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        send_whatsapp_alert(sos_message.strip())
        return jsonify({"status": "success", "message": "SOS alert sent via WhatsApp."}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


def split_message(message, max_length=1600):
    """
    Splits a message into chunks without breaking mid-word or mid-line.
    """
    lines = message.splitlines()
    chunks = []
    current_chunk = ""

    for line in lines:
        # +1 for the newline character we split on
        if len(current_chunk) + len(line) + 1 <= max_length:
            current_chunk += line + "\n"
        else:
            chunks.append(current_chunk.strip())
            current_chunk = line + "\n"

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


@app.route("/ask", methods=["POST"])
def ask():
    init_memory()
    user_input = request.json.get("message")
    if not user_input:
        return jsonify({"error": "No message provided"}), 400

    # Add user input to history
    session["history"].append(f"User: {user_input}")

    docs = vectorstore.similarity_search(user_input, k=3)
    context = "\n\n".join(doc.page_content for doc in docs)

    full_prompt = f"""
You are a health literacy assistant. Your role is to explain symptoms, provide educational insight, and suggest general first-aid steps.
Use the content from the provided medical textbook to help the user understand what might be happening.

Do not diagnose. Do not mention being an AI. Do not suggest calling emergency services unless absolutely necessary.
Keep responses informative and based on textbook content.

--- Medical Reference ---
{context}

--- Conversation History ---
{chr(10).join(session["history"])}

Respond helpfully.
"""


    response = llm.invoke(full_prompt)

    # Save bot reply
    session["history"].append(f"Bot: {response.content}")
    
    return jsonify({"response": response.content})


@app.route("/reset", methods=["POST"])
def reset():
    session.pop("history", None)
    return jsonify({"message": "Session reset successful."})



@app.route("/upload", methods=["POST"])
def upload():
    if "file" not in request.files:
        return jsonify({"error": "No file part"}), 400

    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "No selected file"}), 400

    try:
        # Save the uploaded file to a temporary path (closed immediately)
        temp_path = os.path.join(tempfile.gettempdir(), file.filename)
        file.save(temp_path)

        # Process OCR and generate advice
        extracted_data = extract_information_from_image(temp_path)
        advice = generate_doctor_advice(extracted_data)

        extracted_text = json.dumps(extracted_data, indent=2)
        full_message = f"""*Medical Report Analysis*
        *Advice:*\n{advice}
        """

        # Split message if too long
        message_parts = split_message(full_message, max_length=1600)
        for i, part in enumerate(message_parts):
            header = f"üìÑ Report Part {i+1} of {len(message_parts)}:\n\n"
            send_whatsapp_alert(header + part)

        return jsonify({
            "extracted_data": extracted_data,
            "advice": advice
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    finally:
        if os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except Exception as cleanup_error:
                print(f"Could not delete temp file: {cleanup_error}")

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))

